{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Classification from EEG\n",
    "\n",
    "Data can be found here: https://ucmerced.box.com/s/m8tpshib6zztio9q34h9fh9ikhhl4a3m\n",
    "\n",
    "Nam Le Dong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following analyes EEG data taken in experiments where participants where exposed to light and sound events. This code cleans that 32 channel EEG data and uses a Convolutional Neural network (CNN) model to classify the time following light or sound events by which event occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random seed for reproducibility\n",
    "import random\n",
    "seed=42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1 and events1 are the test data from a single person\n",
    "# code assumes eeg1 and events1 are csv files in the current working directory\n",
    "\n",
    "eeg1 = pd.read_csv(\"eeg1.csv\", delimiter=\"\\t\")\n",
    "new_columns = eeg1.columns.values \n",
    "new_columns[0] = 'time'     \n",
    "new_columns[33] = 'sample' \n",
    "eeg1.columns = new_columns\n",
    "\n",
    "events1 = pd.read_csv(\"events1.csv\") #, delimiter=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>FP1</th>\n",
       "      <th>FPZ</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FZ</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>FC5</th>\n",
       "      <th>...</th>\n",
       "      <th>P7</th>\n",
       "      <th>P3</th>\n",
       "      <th>PZ</th>\n",
       "      <th>P4</th>\n",
       "      <th>P8</th>\n",
       "      <th>POZ</th>\n",
       "      <th>O1</th>\n",
       "      <th>OZ</th>\n",
       "      <th>O2</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-11.5744</td>\n",
       "      <td>-6.2119</td>\n",
       "      <td>-0.5371</td>\n",
       "      <td>-7.6891</td>\n",
       "      <td>-6.4002</td>\n",
       "      <td>2.1904</td>\n",
       "      <td>6.8447</td>\n",
       "      <td>7.4843</td>\n",
       "      <td>3.7198</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4748</td>\n",
       "      <td>6.0962</td>\n",
       "      <td>9.7316</td>\n",
       "      <td>6.9366</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>6.3835</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>3.3984</td>\n",
       "      <td>2.0209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9766</td>\n",
       "      <td>-15.1140</td>\n",
       "      <td>-7.7239</td>\n",
       "      <td>-1.9460</td>\n",
       "      <td>-7.8315</td>\n",
       "      <td>-4.6182</td>\n",
       "      <td>1.0912</td>\n",
       "      <td>5.3037</td>\n",
       "      <td>5.1452</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7514</td>\n",
       "      <td>7.2011</td>\n",
       "      <td>10.3467</td>\n",
       "      <td>7.1375</td>\n",
       "      <td>2.0744</td>\n",
       "      <td>7.3299</td>\n",
       "      <td>1.4737</td>\n",
       "      <td>4.6642</td>\n",
       "      <td>3.4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.9531</td>\n",
       "      <td>-18.3309</td>\n",
       "      <td>-9.1054</td>\n",
       "      <td>-3.4390</td>\n",
       "      <td>-7.5311</td>\n",
       "      <td>-2.7676</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>3.3870</td>\n",
       "      <td>2.3100</td>\n",
       "      <td>-2.3004</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6490</td>\n",
       "      <td>8.2395</td>\n",
       "      <td>10.7950</td>\n",
       "      <td>7.1424</td>\n",
       "      <td>1.7050</td>\n",
       "      <td>8.1615</td>\n",
       "      <td>2.2646</td>\n",
       "      <td>5.8274</td>\n",
       "      <td>4.7750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.9297</td>\n",
       "      <td>-21.0045</td>\n",
       "      <td>-10.2607</td>\n",
       "      <td>-4.9292</td>\n",
       "      <td>-6.7343</td>\n",
       "      <td>-0.9010</td>\n",
       "      <td>-1.4752</td>\n",
       "      <td>1.1906</td>\n",
       "      <td>-0.9090</td>\n",
       "      <td>-4.8420</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1156</td>\n",
       "      <td>9.1695</td>\n",
       "      <td>11.0409</td>\n",
       "      <td>6.9196</td>\n",
       "      <td>1.1848</td>\n",
       "      <td>8.8291</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>6.8464</td>\n",
       "      <td>5.8887</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.9062</td>\n",
       "      <td>-22.9476</td>\n",
       "      <td>-11.1097</td>\n",
       "      <td>-6.3279</td>\n",
       "      <td>-5.4243</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>-2.8213</td>\n",
       "      <td>-1.1634</td>\n",
       "      <td>-4.3681</td>\n",
       "      <td>-6.9461</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1362</td>\n",
       "      <td>9.9566</td>\n",
       "      <td>11.0647</td>\n",
       "      <td>6.4538</td>\n",
       "      <td>0.4847</td>\n",
       "      <td>9.2956</td>\n",
       "      <td>3.4476</td>\n",
       "      <td>7.6932</td>\n",
       "      <td>6.6995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time      FP1      FPZ     FP2      F7      F3      FZ      F4      F8  \\\n",
       "0  0.0000 -11.5744  -6.2119 -0.5371 -7.6891 -6.4002  2.1904  6.8447  7.4843   \n",
       "1  0.9766 -15.1140  -7.7239 -1.9460 -7.8315 -4.6182  1.0912  5.3037  5.1452   \n",
       "2  1.9531 -18.3309  -9.1054 -3.4390 -7.5311 -2.7676 -0.1498  3.3870  2.3100   \n",
       "3  2.9297 -21.0045 -10.2607 -4.9292 -6.7343 -0.9010 -1.4752  1.1906 -0.9090   \n",
       "4  3.9062 -22.9476 -11.1097 -6.3279 -5.4243  0.9241 -2.8213 -1.1634 -4.3681   \n",
       "\n",
       "      FC5   ...         P7      P3       PZ      P4      P8     POZ      O1  \\\n",
       "0  3.7198   ...     3.4748  6.0962   9.7316  6.9366  2.3333  6.3835  0.5040   \n",
       "1  0.5942   ...     6.7514  7.2011  10.3467  7.1375  2.0744  7.3299  1.4737   \n",
       "2 -2.3004   ...     9.6490  8.2395  10.7950  7.1424  1.7050  8.1615  2.2646   \n",
       "3 -4.8420   ...    12.1156  9.1695  11.0409  6.9196  1.1848  8.8291  2.9057   \n",
       "4 -6.9461   ...    14.1362  9.9566  11.0647  6.4538  0.4847  9.2956  3.4476   \n",
       "\n",
       "       OZ      O2  sample  \n",
       "0  3.3984  2.0209     NaN  \n",
       "1  4.6642  3.4500     NaN  \n",
       "2  5.8274  4.7750     NaN  \n",
       "3  6.8464  5.8887     NaN  \n",
       "4  7.6932  6.6995     NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>latency</th>\n",
       "      <th>type</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>66164</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>66760</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>67374</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>67989</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  latency  type  duration\n",
       "0       1        1     0         0\n",
       "1       2    66164     6         0\n",
       "2       3    66760     6         0\n",
       "3       4    67374     6         0\n",
       "4       5    67989     6         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4283, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3469303, 34)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample of the data to ease building the model, unused in final run\n",
    "eeg1_smol = eeg1[0:785000]\n",
    "events1_smol = events1[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785000, 34)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1_smol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events1_smol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data generator, unused in final run\n",
    "\n",
    "def generate_eeg(samples, time_steps, n_features, event_types):\n",
    "    # samples is Int number of trials \n",
    "    # time_steps is Int length of each trial in ms\n",
    "    # n_features is Int number of EEG channels\n",
    "    # event_types is Int number of stimula like lights and flashes\n",
    "    signals = generate_signals(samples, time_steps, n_features)\n",
    "    events = generate_events(event_types, samples)\n",
    "    events_1hot = one_hot_events(events)\n",
    "    return signals, events_1hot\n",
    "\n",
    "# helper function (generate_eeg) for making EEG signal data\n",
    "def generate_signals(samples, time_steps, n_features):\n",
    "    # data types same as main function\n",
    "    signals = np.random.random((samples, time_steps, n_features))\n",
    "    return signals\n",
    "\n",
    "# helper function (generate_eeg) for making one sample per event an\n",
    "def generate_events(event_types, samples):\n",
    "    # data types same as main function\n",
    "    events = np.random.randint(1, event_types, samples)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in eeg dataframe and event dataframe, cleans them, 1hot encodes the events\n",
    "def clean_eeg(eeg, events, event_interval_length, eeg_slice_length):\n",
    "    #event_list = []\n",
    "    array_list = [] \n",
    "    index_list = []\n",
    "    eeg = standardize_eeg(eeg) # function for standardizing the eeg readings\n",
    "    #events_new = build_zero_events(events)\n",
    "    # iterate over the rows of the events and slice out the corresponding eeg data\n",
    "    for index, row in itertools.islice(events.iterrows(), event_interval_length): # loop through events data\n",
    "        #build_event_list(row, event_list) #\n",
    "        tmin, tmax = build_event_intervals(row, events)\n",
    "        eeg_slice = cut_event_intervals(eeg, tmin, tmax)\n",
    "        array_list, index_list = build_array(eeg_slice, eeg_slice_length, \n",
    "                                             index, index_list, array_list)\n",
    "    y_int = events.iloc[index_list] # take the event types for the correct index\n",
    "    y_int = y_int['type'].values    # take just the event types as an array\n",
    "    #y_int = y_int.as_matrix()            # save the event types as a matrix\n",
    "    #y, lb = one_hot_events(y_int)        # one-hot the event types and save the binarizer\n",
    "    X = np.stack(array_list, axis = 0)   # stack the arrays so the whole thing is 3D\n",
    "    return X, y_int                     # return the data, outputs, and the binarizer\n",
    "    \n",
    "        \n",
    "def build_event_list(row, event_list):\n",
    "    # helper function to pull event types out of event data in the right order\n",
    "    event_type = getattr(row, \"type\")\n",
    "    event_list.append(event_type)\n",
    "        \n",
    "def build_event_intervals(row, events):\n",
    "    # helper function to get the time intervals associated with each event\n",
    "    tmin = getattr(row, \"latency\")\n",
    "    tmin_in = getattr(row, \"number\")\n",
    "    tmax_in = tmin_in + 1\n",
    "    tmax = events1.loc[tmax_in, \"latency\"]\n",
    "    return tmin, tmax\n",
    "\n",
    "def cut_event_intervals(eeg, tmin, tmax):\n",
    "    # helper function to slice up the eeg data so each slice is associated with one event\n",
    "    eeg_slice = eeg.loc[(eeg[\"time\"] > tmin) & (eeg[\"time\"] < tmax)]\n",
    "    eeg_slice.drop([\"time\", \"sample\"], axis = 1, inplace = True)\n",
    "    return eeg_slice\n",
    "    \n",
    "def build_array(eeg_slice, eeg_slice_length, index, index_list, array_list):\n",
    "    # helper function to build an array out of the eeg slices and pad them out to a standard length\n",
    "    if len(eeg_slice) < eeg_slice_length:\n",
    "        index_list.append(index)\n",
    "        eeg_matrix = eeg_slice.as_matrix()\n",
    "        padded_matrix = np.pad(eeg_matrix, ((0, eeg_slice_length - len(eeg_matrix)), (0,0)),\n",
    "                                   'constant', constant_values=0)\n",
    "        array_list.append(padded_matrix)\n",
    "    return array_list, index_list\n",
    "\n",
    "def one_hot_events(events):\n",
    "    # helper function for one-hot encoding the events\n",
    "    events_list = list(events)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(events_list)\n",
    "    events_1hot = lb.transform(events_list)\n",
    "    return events_1hot, lb\n",
    "\n",
    "def invert_one_hot(events, lb):\n",
    "    # function for decoding one-hot, binarizer made in one_hot_events\n",
    "    inv_events = lb.inverse_transform(events)\n",
    "    return inv_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_eeg(eeg_data):\n",
    "    # breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\n",
    "    column_list = eeg_data.columns[1:33]\n",
    "    time = eeg_data['time']\n",
    "    sample = eeg_data['sample']\n",
    "    eeg_array = eeg_data[column_list]\n",
    "    eeg_stnd = scale_data(eeg_array)\n",
    "    eeg_stnd_df = pd.DataFrame(eeg_stnd, index=eeg_data.index, columns=column_list)\n",
    "    eeg_stnd = pd.concat([time, eeg_stnd_df, sample], axis =1)\n",
    "    return eeg_stnd\n",
    "\n",
    "def scale_data(unscaled_data):\n",
    "    # helper function for standardize_eeg, fits a scaler and transforms the data \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(unscaled_data)\n",
    "    scaled_data = scaler.transform(unscaled_data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is unused code for breaking up the \"nothing happened\" periods of the eeg data \n",
    "# to associate with \"type 0\" events. \n",
    "\n",
    "import math\n",
    "time_steps = 1300\n",
    "\n",
    "def build_zero_events(event_data, time_steps=time_steps):\n",
    "    new_events = build_new_events(event_data, time_steps)\n",
    "    events = zero_events(event_data, new_events)\n",
    "    return events\n",
    "\n",
    "\n",
    "def build_new_events(event_data, time_steps= time_steps):\n",
    "    first_event_time = event_data['latency'].loc[1]\n",
    "    number_new_intervals = math.floor(first_event_time / time_steps)\n",
    "    df = pd.DataFrame(columns=['number', 'latency', 'type', 'duration'],index = range(number_new_intervals) )\n",
    "    latency = 0\n",
    "    for t in range(number_new_intervals):\n",
    "        latency += 1300\n",
    "        df.loc[t].latency = latency\n",
    "        df.loc[t].type = 0\n",
    "    return df\n",
    "\n",
    "def zero_events(event_data, new_events):\n",
    "    events_zeros = event_data[event_data.latency != 1]\n",
    "    events_zeros= new_events.append(events_zeros)\n",
    "    events_zeros = events_zeros.reset_index(drop=True)\n",
    "    events_zeros['number'] = events_zeros.index + 1\n",
    "    return events_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset parameters\n",
    "\n",
    "# define model parameters\n",
    "samples = 3625  # how many trials of eeg data\n",
    "n_features = 32  # how many channels of eeg in each sample\n",
    "time_steps = 1300 # how many ms was each sample run for\n",
    "event_types = 2 #len(set(y))  # how many different event types (light, sound, etc) are there # 6 large, 4 smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# get the data into useable form and store as X and y\n",
    "X, y = clean_eeg(eeg1, events1, samples, time_steps)  #4250 long, 998 short, 4330 long enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3554, 1300, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22334067,  0.16348891,  0.2673775 , ...,  0.13175228,\n",
       "         0.25368819, -0.3451777 ],\n",
       "       [ 0.21936408,  0.13216201,  0.25447713, ...,  0.0046344 ,\n",
       "         0.20014994, -0.35425198],\n",
       "       [ 0.21598459,  0.10373928,  0.23813144, ..., -0.14758523,\n",
       "         0.12719416, -0.36555702],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3554,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the minor event types. There were only a couple hundred examples of each, whereas the used events had a \n",
    "# couple thousand examples\n",
    "remove_list = [0,2,4,5,6]              # designate unwanted event types\n",
    "drop_list = np.isin(y, remove_list)    # create a list of indices associated with unwanted events                  \n",
    "drop_array = np.array(drop_list)       # make the list of indices to drop into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X, y's with the unwanted events removed\n",
    "y_short_int = y[np.isin(y,remove_list, invert=True)]\n",
    "X_short = X[np.isin(y, remove_list, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the y data without the unwanted events\n",
    "y_short, lb = one_hot_events(y_short_int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3056, 1300, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3056, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# use strat. shuffle split to get indices for test and training data \n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=seed)\n",
    "sss.get_n_splits(X_short, y_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the indices generated by stratified shuffle split and make the test and training datasets\n",
    "for train_index, test_index in sss.split(X_short, y_short):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_short[train_index], X_short[test_index]\n",
    "    y_train, y_test = y_short[train_index], y_short[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2444, 1300, 32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 1300, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2444, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2444/2444 [==============================] - 3s 1ms/step - loss: 1.9653 - acc: 0.4861\n",
      "Epoch 2/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.7792 - acc: 0.5327\n",
      "Epoch 3/50\n",
      "2444/2444 [==============================] - 1s 499us/step - loss: 0.6991 - acc: 0.5790\n",
      "Epoch 4/50\n",
      "2444/2444 [==============================] - 1s 499us/step - loss: 0.6677 - acc: 0.6072\n",
      "Epoch 5/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.6497 - acc: 0.6322\n",
      "Epoch 6/50\n",
      "2444/2444 [==============================] - 1s 499us/step - loss: 0.6417 - acc: 0.6244\n",
      "Epoch 7/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.6212 - acc: 0.6698\n",
      "Epoch 8/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.6255 - acc: 0.6624\n",
      "Epoch 9/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.5656 - acc: 0.7324\n",
      "Epoch 10/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.4847 - acc: 0.8011\n",
      "Epoch 11/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.3502 - acc: 0.8773\n",
      "Epoch 12/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.2553 - acc: 0.9141\n",
      "Epoch 13/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.1786 - acc: 0.9444\n",
      "Epoch 14/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.1284 - acc: 0.9587\n",
      "Epoch 15/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0906 - acc: 0.9763\n",
      "Epoch 16/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0937 - acc: 0.9714\n",
      "Epoch 17/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0778 - acc: 0.9779\n",
      "Epoch 18/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0892 - acc: 0.9791\n",
      "Epoch 19/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.0692 - acc: 0.9787\n",
      "Epoch 20/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0467 - acc: 0.9857\n",
      "Epoch 21/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.0422 - acc: 0.9906\n",
      "Epoch 22/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.0315 - acc: 0.9922\n",
      "Epoch 23/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0315 - acc: 0.9918\n",
      "Epoch 24/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.0211 - acc: 0.9943\n",
      "Epoch 25/50\n",
      "2444/2444 [==============================] - 1s 524us/step - loss: 0.0175 - acc: 0.9971\n",
      "Epoch 26/50\n",
      "2444/2444 [==============================] - 1s 539us/step - loss: 0.0147 - acc: 0.9967\n",
      "Epoch 27/50\n",
      "2444/2444 [==============================] - 1s 546us/step - loss: 0.0129 - acc: 0.9971\n",
      "Epoch 28/50\n",
      "2444/2444 [==============================] - 1s 510us/step - loss: 0.0165 - acc: 0.9959\n",
      "Epoch 29/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0093 - acc: 0.9988\n",
      "Epoch 30/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0085 - acc: 0.9988\n",
      "Epoch 31/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0077 - acc: 0.9988\n",
      "Epoch 32/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 33/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0126 - acc: 0.9980\n",
      "Epoch 34/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0278 - acc: 0.9926\n",
      "Epoch 35/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0124 - acc: 0.9967\n",
      "Epoch 36/50\n",
      "2444/2444 [==============================] - 1s 521us/step - loss: 0.0132 - acc: 0.9955\n",
      "Epoch 37/50\n",
      "2444/2444 [==============================] - 1s 518us/step - loss: 0.0095 - acc: 0.9980\n",
      "Epoch 38/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 39/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 40/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 41/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "2444/2444 [==============================] - 1s 499us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0051 - acc: 0.9975\n",
      "Epoch 44/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 47/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "2444/2444 [==============================] - 1s 505us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "2444/2444 [==============================] - 1s 511us/step - loss: 0.0057 - acc: 0.9975\n",
      "612/612 [==============================] - 0s 740us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization, Embedding, Flatten, Conv1D, Activation, MaxPooling1D\n",
    "\n",
    "# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n",
    "\n",
    "model = Sequential()\n",
    "# CNN 1\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, \n",
    "          input_shape=(time_steps, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))    \n",
    "model.add(Dropout(0.2))\n",
    "    \n",
    "# CNN 2\n",
    "model.add(Conv1D(filters=64,  kernel_size=3, padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))    \n",
    "model.add(Dropout(0.2))\n",
    "        \n",
    "# CNN 3\n",
    "model.add(Conv1D(filters=128,  kernel_size=3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))    \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, epochs=50)\n",
    "score = model.evaluate(X_test, y_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18964731654310538, 0.9689542530408872]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
